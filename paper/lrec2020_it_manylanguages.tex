\documentclass[10pt, a4paper]{article}

\usepackage{lrec}
\usepackage{multibib}
\newcites{languageresource}{Language Resources}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}

\usepackage{booktabs}
\usepackage[symbol]{footmisc}

% for eps graphics
% 
\usepackage{epstopdf}
\usepackage[utf8]{inputenc}

%\usepackage{hyperref}
\usepackage{xstring}

\usepackage{color}

\definecolor{lightgray}{rgb}{0.83, 0.83, 0.83}

\newcommand{\secref}[1]{\StrSubstitute{\getrefnumber{#1}}{.}{ }}


\title{Exploiting Cross-Lingual Hints to Discover Event Pronouns}

\name{Sharid Loáiciga$^{1*}$, Christian Hardmeier$^2$  \& Asad Sayeed$^3$}

\address{$^1$ CoLab Potsdam, Department of Linguistics, University of Potsdam \\  
$^2$ Department of Linguistics and Philology, Uppsala University \\
$^3$ CLASP, Department of Philosophy, Linguistics and Theory of Science, University of
Gothenburg  \\ 
sharid.loaiciga@gmail.com, christian.hardmeier@lingfil.uu.se, asad.sayeed@gu.se}


\abstract{ Non-nominal co-reference is much less studied than nominal
coreference, partly because of the lack of annotated corpora. In this paper, we
have explored the possibility to exploit parallel multilingual corpora as a
means of cheap supervision for the task of it-disambiguation. We found that only a very specific `event' reading is discernible using our approach.  \\ \newline
\Keywords{`it', reference, Europarl corpus} }


\begin{document}


\maketitleabstract

\section{Introduction}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\footnotetext[1]{Work completed while the first author was affiliated at the
Department of Philosophy, Linguistics and Theory of Science, University of Gothenburg.}


Depending on the context, the English pronoun \textit{it} can express anaphoric
reference with a nominal entity antecedent or with a
non-nominal antecedent such as an event. It can also be used
pleonastically. The examples \ref{ex:nominal} to \ref{ex:pleo} below illustrate
these different readings using English passages from the Europarl corpus and
their French parallel translations. Nominal coreference has been studied
extensively, but work on the automatic recognition of non-nominal anaphora is
scarce, as are annotated data sets.

In this paper, we evaluate the potential of multilingual parallel data to create artificial 
training data  
for the classification of different readings of `it', by exploiting the hypothesis that languages 
have different preferences to encode
the competing readings. Multilingual parallel data serves thus as a cheap
supervision signal. 

While developing the method, we found that the `event' reading can be easily
predicted, as the languages studied here have a similar strategy for their translation. 
Despite this, `event' uses of the pronoun `it' are not enough to generalize to
other types of non-nominal reference. Deictic uses in particular, are expressed
very differently and are therefore difficult to normalize.

%Anaphoric non-nominals are typically discarded in the non-referring basket
%together with pleonastics. 
%
%In this paper we mine examples automatically.
%
\begin{enumerate}

\item\label{ex:nominal} \textsc{Entity reading}

This year we celebrate the 10th anniversary of the euro and on 1 January 2009
Slovakia became the 16th member of the euro area. \textbf{My country} has surrendered a
part of its identity, but \textbf{it} has done so with pride.

\textit{Cette année, nous célébrons le 10e anniversaire de l'euro et, le 1er janvier
2009, la Slovaquie est devenue le 16e membre de la zone euro. \textbf{Mon pays} a
abandonné une partie de son identité, mais \textbf{il} l'a fait avec fierté}


%The infectious disease that's killed more humans than any other is
%\textbf{malaria}.  \textbf{It}'s carried in the bites of infected mosquitos.

%\textit{Jene Krankheit, die mehr Leute als jede andere umgebracht hat, ist
%Malaria gewesen. \textbf{Sie} wird über die Stiche von infizierten Moskitos
%übertragen.}

\item\label{ex:event}\textsc{Event reading}

The European Parliament has always taken a vigorous stance against racism and
ethnic intolerance. I appeal to you, as Members of this House, to do
\textbf{it} once again and support our written declaration condemning Turkish racism against Bulgarians.

\textit{Le Parlement européen a toujours pris des positions véhémentes contre le racisme
et l'intolérance ethnique. Je fais appel à vous, en tant que membres de cette
Assemblée, pour que vous \textbf{le} fassiez à nouveau, et que vous souteniez notre
déclaration écrite condamnant le racisme turc à l'égard des Bulgares.} 

%But I think \textbf{if we lost everyone with Down syndrome},  \textbf{it} would
%be a catastrophic loss.

%\textit{Aber, wenn wir alle Menschen mit Down-Syndrom verlören, wäre
%\textbf{das}    ein katastrophaler Verlust.}

\item\label{ex:pleo} \textsc{Pleonastic reading}

Since the beginning of October 2008 I have been trying to get speaking time in
the one -minute contributions and I am pleased that I have finally succeeded.
\textbf{It} is interesting that Mr Rogalski has been allowed to speak three times in the meantime. 


\textit{Depuis le début d'octobre 2008, j'ai essayé d'obtenir un temps de parole
dans le cadre des interventions d'une minute et je suis heureux d'avoir
finalement réussi. \textbf{Il} est intéressant que M. Rogalski ait été autorisé à prendre la parole trois fois dans l'intervalle.}



%And  \textbf{it} seemed to me that there were three levels of acceptance that
%needed to take place.

%\textit{Und \textbf{es} schien, dass es drei Stufen der Akzeptanz gibt, die alle
%zum Tragen kommen mussten.}

\end{enumerate}



\section{Related Work}

Reference to non-nominal antecedents has largely been a niche area in NLP
research, which is extensively surveyed in a recent article by
\newcite{kolhatkar-etal-2018-survey}. The most extensive annotation efforts in
the field of coreference resolution have focused on nominal coreference.
OntoNotes \cite{Pradhan:2013}, the largest and most frequently used corpus for
training coreference resolution systems, for instance, only includes verbs if
``they can be co-referenced with an existing noun phrase'' according to its
guidelines. Corpora with a richer annotation of event pronouns exist, but are
much smaller. The most important resource is the ARRAU corpus
\cite{poesio-etal-2018-anaphora}, whose size amounts to about 20\% of version~5
of OntoNotes. ParCorFull \cite{Lapshinova-Koltunski-Hardmeier-Krielke2018} also
contains annotations of event pronouns.

The scarcity of manually annotated resources has led to the use of artificial
training data for the resolution of non-nominal anaphora.
\newcite{kolhatkar-etal-2013-interpreting} study the resolution of anaphoric
shell nouns such as `this issue' or `this fact' by exploiting
cataphoric instances such as `the fact that\ldots'.
\newcite{marasovic-etal-2017-mention} construct training examples based on
specific patterns of verbs governing embedded sentences. As far as we know, the
use of multilingual data for automatic data creation is novel in our work.


%They give the following example:
%
% Sales of passenger cars [grew]x 22\%. [The strong growth]x followed
% year-to-year increases.
% 
Before the breakthrough of neural end-to-end systems in coreference resolution
\cite{Lee:2017}, coreference resolvers needed to do explicit mention
classification in order to exclude non-referential mentions before any
resolution was attempted. In this context, the pronoun `it' has been targeted,
as many of its uses are non-referential. \newcite{Evans2001} proposes the
classification of the pronoun `it' into seven classes using contextual features.
\newcite{Boyd2005} report similar results of around 80\% accuracy using more
complex syntactic patterns. \newcite{Bergsma:2011} describe a system for
identifying non-referential pronouns using web $n$-gram features, however
without accounting explicitly for event reference.

The many uses of `it' are also particularly relevant in dialog texts, where
event reference is much more common than in news data. In this context,
\newcite{muller-2007-resolving} proposes a disambiguation of `it' together with
the deictic pronouns `this' and `that'.  Finally, \newcite{Lee2016} create a corpus
for it-disambiguation in question answering, a domain close to dialog. It is
worth noting that current coreference resolution systems are not trained to
manage dialog data.

More recently,  \newcite{Loaiciga2017itrnn} proposed a semi-supervised setup
based on a combination of syntactic and semantic features used in a two-step
classification approach where a maximum entropy classifier is used first and a
recurrent recursive network (RNN) after. \newcite{yaneva-etal-2018-classifying},
on the other hand, report on experiments using features from eye gaze that prove
to be more effective than any of the other types of features reported in
previous works.




\section{Method}

We used the corpus Europarl \cite{Koehn2005} v8 as found in the OPUS collection
\cite{TIEDEMANN12.463}. OPUS also includes parsed and sentence-level and
word-level alignments files for the Europarl corpus. We used all 15 languages
paired with English as the source language. The languages are German, Finnish, Swedish, Italian, Latvian, Dutch, Hungarian, Polish, Slovenian, Portuguese, Slovak, Romanian, Estonian, and Spanish.  

The overall method is as follows:

\begin{enumerate}\setlength\itemsep{1em}

\item Europarl is a parallel corpus of translations
between the language pairs, but the amount of data from one language to another
varies. Therefore we began by extracting only the set of common sentences
accross all languages. This already reduced the data from 2,039,537 segments to
286,053.

\item  Next, we relied on the English parsed files to
identify all instances of the pronoun `it'.

\item We then used the word-level alignment files to
extract the aligned translation in all the languages.

Word alignment is not perfect. One-to-one correspondences are unstable for
particles and other small word forms, in particular if they depend on verbs and might
be translated by just one verb form, virtually disappearing then from the
translation. Pronouns in particular, depending on the language, might not be
translated for instance if the language is a pro-drop one, or they might be
translated as a full nominal phrase, because the language has a different use of
pronouns.

For improving the quality of the word alignments, we used a window of -3 and
+3 tokens before and after the position of the aligned token. This means that if
the translated token was not a pronoun (we have POS information from the parsing
files), we would search for a pronoun translation within the window range.

\item We aim at creating English data in which the instances of
`it' are annotated as `entity', `event' or `pleonastic'. While the three
readings use the same pronoun in English, we rely on the assumption that they
have at least partially different realizations in the other languages.

For the expletives, we took all instances of `it' analyzed as expletives in the
parsed files. These files have been processed using universal dependencies v2.0
(UDPipe parser, models from 2017-08-01), which includes the dedicated dependency
relation \texttt{expl} \cite{bouma-etal-2018-expletives}.

Taking advantage of the parallel data, we decided to use French as a seed language, and
consider all instances translated with the neutral demonstrative pronouns
\textit{cela}, \textit{ceci} or \textit{ça} as events. In French, these pronoun
are typically used to reference proposition or phrases. For the entity nominal
case, we took the French translations \textit{elle} and \textit{il}. From 69,126
`it' pronouns, we labeled 22,615 instances, corresponding to approximately 30\%
(Tables \ref{tab:classrules} and \ref{tab:resultinglabels}).

\item Last, translations from the other 14 languages than French are used as features for
the classification task. Each line in Figure \ref{fig:featuresexample}
represents a feature vector.

\end{enumerate}




\begin{table}\centering \begin{tabular}{ccc} \toprule \textbf{English} &
\textbf{French} &  \textbf{Class} \\ \midrule it &  \textit{elle/il}  & entity\\
it & \textit{cela/ça/ceci} & event  \\ it  &  -- &pleonastic \\
\bottomrule
\end{tabular} 
\caption{Summary of the translation assumptions for labeling the
classes. }\label{tab:classrules} 
\end{table}



\begin{table}[h!]\centering \begin{tabular}{ccc}
\multicolumn{3}{c}{\textbf{Label}}\\ 
\toprule 
Entity & Event & Pleonastic \\
\midrule 
11,483 & 910 &10,222\\ 
\bottomrule 
\end{tabular} 
\caption{Resulting distribution after automatic labeling. }
\label{tab:resultinglabels} 
\end{table}


\begin{center} \begin{figure*} \resizebox{\linewidth}{!}{
\begin{tabular}{*{14}{l}}
\toprule
%\textbf{English} & \textbf{French} &  \textbf{Class} &&&&&&&&&&& \\ \midrule it
%&  \textit{elle/il}  & entity  &&&&&&&&&&& \\ it & \textit{cela/ça/ceci} &
%event  &&&&&&&&&&& \\ it  &  --  &&&&&&&&&&& \\ \midrule
\multicolumn{14}{c}{\textbf{Features}}\\ \midrule DE & ES & ET & FI &HU& IT &
LV&NL & PL & PT &  RO& SK& SL& SV  \\ &&&&&&&&&&&&&\\ 

\textit{empty}&\textit{idea}&\textit{seda}&\textit{empty}&\textit{képeznie}&\textit{essenza}&\textit{es}&\textit{dit}&\textit{dodać}&\textit{adaug}&\textit{že}&\textit{empty}&\textit{detta}\\

\textit{du}&\textit{usted}&\textit{sa}&\textit{empty}&\textit{te}&\textit{l'}&\textit{empty}&\textit{u}&\textit{empty}&\textit{empty}&\textit{eşti}&\textit{ty}&\textit{empty}&\textit{du}\\

\textit{empty}&\textit{señor}&\textit{ja}&\textit{empty}&\textit{.}&\textit{-}&\textit{empty}&\textit{ik}&\textit{cohn-bendit}&\textit{cohn-bendit}&\textit{îi}&\textit{a}&\textit{gospod}&\textit{sluta}\\

\textit{empty}&\textit{que}&\textit{juhataja}&\textit{siirtämisestä}&\textit{úr}&\textit{presidente}&\textit{empty}&\textit{de}&\textit{!}&\textit{é}&\textit{,}&\textit{je}&\textit{predsednik}&\textit{det}\\

\textit{empty}&\textit{es}&\textit{üksluine}&\textit{ne}&\textit{dolog}&\textit{in}&\textit{tas}&\textit{empty}&\textit{co}&\textit{empty}&\textit{ce}&\textit{spôsobom}&\textit{govoriti}&\textit{allt}\\
									
 \bottomrule
 \end{tabular}} \caption{Exemplification of the extracted
 features.}\label{fig:featuresexample} 
 \end{figure*} 
 \end{center}


A manual analysis of a sample of 600 instances reveals that the main problem 
seems to be the large number of examples that cannot be labeled (column `Unknown'). 
In addition, there is a natural imbalance in the classes (nominal and pleonastic are more
common than events in previous work) that seems to be accentuated by the
automatic labeling. Concerning the quality of the annotation, it can
be seen in Table \ref{tab:manualsample600} that the automatic labeling achieves
approximately 20\% accuracy. We believe that this is mainly due to the
combination of two factors: word-alignment issues and many different
translations different from the assumptions we made by using French as the seed language.  

\begin{table}[h!]\centering 
\begin{tabular}{ccccc} 
\toprule 
&Entity & Event &Pleonastic & Unknown \\ 
\midrule Entity &   56  &  5   &   0     &  259  \\ 
Event &    5  &  6   &  0  &  23\\ 
Pleonastic& 45 & 1&  71&  129\\
\bottomrule 
\end{tabular} \caption{Manual evaluation of a sample of 600
instances.}\label{tab:manualsample600} 
\end{table}




%\begin{table} \begin{tabular}{cccc} \multicolumn{4}{c}{\textbf{MaxEnt with
%oversampling}}\\ \toprule
% & Precision & Recall & Accuracy \\
%\midrule Entity & 0.73 &0.68&    0.80 \\ Event &0.91 & 1.0 & (8,277/10,347) \\
%Pleonastic &  0.74 & 0.72 & \\ \bottomrule \end{tabular}
%\caption{Classification results using bootstrap resampling in a manually
%annotated sample of 600 instances.} \end{table}
%
%
%
%
\section{Classification Experiments}

We used 22,554 generated examples in a classification setting. All the experiments were completed using the implementations of the \texttt{scikit-learn} library, including their \texttt{train\_test\_split} function. 

In a first experiment, we use the generated data tor predict one of the three automatically generated labels: `entity', `event' or `pleonastic'. We report results using a maximum entropy classifier, although replication experiments using a SVM and a Naive Bayes classifier yielded very similar results. 


\begin{table}[h!]\centering
\begin{tabular}{ccc}
\toprule
\textbf{Train} & \textbf{Test} & \textbf{Total} \\
\midrule
15,698 & 6,728 & 22,426 \\
\bottomrule
\end{tabular}
\caption{Data set split for the classification experiments. }
\end{table}

 Although the results using the automatic labels seem reasonable (Table  \ref{tab:maxentautomatic}), when using the same model to predict the manually annotated sample of 600 instances, we see a dramatic decrease in performance, in particular for the `event' class. As mentioned before, this class has a natural low frequency, which makes it more difficult to predict. 

\begin{center} \begin{table}[h!]\centering 
\begin{tabular}{l ccc}
\multicolumn{4}{c}{ \textbf{Automatically annotated data}}\\ 
\toprule
\textbf{MaxEnt}& Precision & Recall & Accuracy \\ 
\midrule 
\textit{it}-Entity &0.70 & 0.75 &   0.70\\
\textit{it}-Event & 0.44 & 0.15 & (4,710/6,728) \\
\textit{it}-Pleonastic & 0.70 & 0.68&   \\ 
\midrule & & & \\
\multicolumn{4}{c}{\textbf{Manually annotated sample}}  \\ 
\midrule
\textbf{MaxEnt}& Precision & Recall & Accuracy \\ 
\midrule 
Entity &0.55 & 0.84 &0.54\\ 
Event &0.0 & 0.0 & (318/600)\\ 
Pleonastic & 0.50 & 0.22 & \\ 
\bottomrule
\end{tabular} \caption{Classification results using a Maximum Entropy
classifier.} 
\end{table}\label{tab:maxentautomatic}
\end{center}

To address the problem of the uneven distribution of the classes, in a second experiment, we used bootstrap with resampling in order to achieve the same number of examples per class. 

\begin{table}[h!]\centering
\begin{tabular}{ccc}
\toprule
\textbf{Event} & \textbf{Entity} & \textbf{Pleonastic} \\
\midrule
11,377 & 11,377 & 11,377 \\
\bottomrule
\end{tabular}
\caption{Equal distribution of the classes for the experiment with oversampling.}
\end{table}

In this second scenario, we obtained a comparable performance for the `entity' and `pleonastic' classes, and almost perfect scores for the `event' class. 

\begin{center} \begin{table}[h!] \begin{tabular}{cccc}
\multicolumn{4}{c}{\textbf{Oversampling of the event class}}\\ 
\toprule
\textbf{MaxEnt}& Precision & Recall & Accuracy \\ 
\midrule 
 Entity & 0.73 &0.67& 0.80 \\ 
 Event & 0.92 & 0.99 & (8,277/10,347) \\ 
  Pleonastic &  0.73 & 0.74 & \\
\bottomrule 
\end{tabular} 
\caption{Classification results using bootstrap
resampling to achieve an even distribution of the classes.}\label{tab:maxentoversampling}
\end{table}
\end{center}


\section{Discussion and Conclusion}

The experiments presented in the previous section seem to suggest that relying on translations as features for the different readings of `it' is a good method but only for a particular type of `event' that has a natural low frequency. Indeed, our method only produces labels for about 30\% of the total amount of pronouns `it' and within this, 'event' has the lowest absolute frequency. 

Further analysis from the output of a decision tree classifier on the same data partition also suggests that this type of events are easily discernible. As shown in Figure \ref{fig:decisiontree}, the top leaves in the tree all contain equivalent translations of either `it' or `this', pronouns associated with `entity' and `event' respectively. 

Although we originally sought to identify non-nominal uses of `it', through developing this method we found that the task is hard because there are many potential
cases. 

Take for instance the following example:

\vspace{1em}

\textsc{English} Madam President , Commissioners , can I say to you that less than a year ago we were debating in this Chamber what we were going to do about global food security , and was there enough food in the world , and we were terribly worried about \textit{it}.

\textsc{French} \textit{Madame la Présidente , Mesdames et Messieurs les Commissaires , permettez -moi de vous rappeler qu' il y a moins d' un an , nous débattions en cette Assemblée de la manière de traiter la sécurité alimentaire mondiale , de la question de savoir si l' on produisait suffisamment de nourriture à l' échelle mondiale , et nous étions extrêmement préoccupés par \textbf{ces questions} .}

\vspace{1em}

In the example the English pronoun `it' refers to all what has previously been mentioned in the long sentence. The French translation, however, prefers a translation with a full lexical noun phrase \textit{ces questions} (these questions) for the same referential relationship. 

The task could be approached semantically by identifying all abstract
nouns referencing actions, nominalizations or eventualities in the text. Or one
could decide to focus on particular syntactic configurations as
\newcite{marasovic-etal-2017-mention}.

\begin{figure}
\begin{verbatim}
 -- see_et<=0.5
|  |--- é_pt<=0.5
|  |  |--- tas_lv<=0.5
|  |  |  |--- to_pl<=0.5
|  |  |  |  |--- este_ro<=0.5
|  |  |  |  |  |--- ez_hu<=0.5
|  |  |  |  |  |  |--- es_es<=0.5
|  |  |  |  |  |  |  |--- den_sv<=0.5
|  |  |  |  |  |  |  |  |--- je_sk<=0.5
|  |  |  |  |  |  |  |  |  |--- to_sk<=0.5
|  |  |  |  |  |  |  |  |  |  |--se_fi<=0.5
\end{verbatim}
\caption{Output of a decision tree classifier. The leaves have the form \texttt{pronoun\_language}.}\label{fig:decisiontree}
\end{figure}

Non-nominal co-reference is much less studied than nominal coreference, partly
because of the lack of annotated corpora. In this paper, we have explored the
possibility to exploit parallel multilingual corpora as a means of cheap
supervision for the task of it-disambiguation. Since pronoun `it' has many
potential uses or readings, we took it a as representative of the non-nominal
coreference phenomenon, however, we found that only a very specific `event' reading 
is discernible using our approach. 

%\cite{Martin-90}
%
%\newcite{Martin-90}
%
%
\section{Acknowledgements}
Christian Hardmeier was supported by the Swedish Research Council under grant 2017-930.
%
%Place all acknowledgements (including those concerning research grants and
%funding) in a separate section at the end of the paper.
%
\section{References}

\bibliographystyle{lrec} \bibliography{lrec2020_it_manylanguages}


%\bibliographystylelanguageresource{lrec}
%\bibliographylanguageresource{languageresource}

\end{document}
